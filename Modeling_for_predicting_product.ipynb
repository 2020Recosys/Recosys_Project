{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tqdm import tqdm_notebook\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.utils import to_categorical\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5243418316899603202\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 480687900724463353\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11342217734406463662\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5811535872\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4805602584206424032\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.6/dist-packages (1.0.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.1)\r\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_가전제품 = pd.read_csv('Y_가전제품.csv')\n",
    "Y_화장품 = pd.read_csv('Y_화장품.csv')\n",
    "Y_패션 = pd.read_csv('Y_패션.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_가전제품= Y_가전제품['가전제품구매']\n",
    "Y_화장품= Y_화장품['화장품구매']\n",
    "Y_패션= Y_패션['패션구매']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_가전제품 = pd.read_csv('가전제품_3d_array.csv')\n",
    "X_화장품 = pd.read_csv('화장품_3d_array.csv')\n",
    "X_패션 = pd.read_csv('패션_3d_array.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    877\n",
       "2     88\n",
       "1     50\n",
       "3     48\n",
       "Name: 가전제품구매, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_가전제품.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94990</th>\n",
       "      <th>94991</th>\n",
       "      <th>94992</th>\n",
       "      <th>94993</th>\n",
       "      <th>94994</th>\n",
       "      <th>94995</th>\n",
       "      <th>94996</th>\n",
       "      <th>94997</th>\n",
       "      <th>94998</th>\n",
       "      <th>94999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1754</td>\n",
       "      <td>29010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308</td>\n",
       "      <td>10185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>29956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1361</td>\n",
       "      <td>7985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1  2  3  4  5  6  7  8  9  ...  94990  94991  94992  94993  \\\n",
       "0  1754  29010  0  0  0  0  1  0  0  0  ...      0      0      0      0   \n",
       "1   308  10185  0  0  0  0  1  0  0  0  ...      0      0      0      0   \n",
       "2    24    314  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "3  1302  29956  0  0  0  0  0  0  0  1  ...      0      0      0      0   \n",
       "4  1361   7985  0  0  0  0  0  0  0  1  ...      0      0      0      0   \n",
       "\n",
       "   94994  94995  94996  94997  94998  94999  \n",
       "0      0      0      0      0      1      0  \n",
       "1      0      0      0      0      1      0  \n",
       "2      0      0      0      0      1      0  \n",
       "3      0      0      1      0      0      0  \n",
       "4      0      0      0      0      1      0  \n",
       "\n",
       "[5 rows x 95000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_가전제품.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_가전제품 = np.asarray(X_가전제품)\n",
    "X_화장품 = np.asarray(X_화장품)\n",
    "X_패션 = np.asarray(X_패션)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1063, 95000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_가전제품.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5000일때 자꾸 커널이 죽음\n",
    "def oversample(X, Y):\n",
    "    max_len = 5000\n",
    "    X_resampled, Y_resampled = smote.fit_resample(X, Y)\n",
    "    X_resampled = X_resampled.reshape(X_resampled.shape[0], max_len, int(X_resampled.shape[1]/max_len))\n",
    "    return X_resampled, Y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_가전제품_resampled, Y_가전제품_resampled =oversample(X_가전제품, Y_가전제품)\n",
    "X_패션_resampled, Y_패션_resampled = oversample(X_패션, Y_패션)\n",
    "X_화장품_resampled, Y_화장품_resampled = oversample(X_화장품, Y_화장품)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 가동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1606, 5000, 19)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_패션_resampled, Y_패션_resampled, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "def get_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(64,input_shape = input_shape))\n",
    "    #model.add(GlobalMaxPool1D())\n",
    "    model.add(Dense(32, activation= 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation= 'relu'))\n",
    "    model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc'])\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with(input_shape, verbose, lr):\n",
    "\n",
    "    # Create the model using a specified hyperparameters.\n",
    "    model = get_model(input_shape)\n",
    "\n",
    "    # Train the model for a specified number of epochs.\n",
    "    optimizer = RMSprop(learning_rate=lr)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with the train dataset.\n",
    "    model.fit(x=X_train,y= y_train ,epochs=1,\n",
    "              batch_size=64, verbose=verbose)\n",
    "\n",
    "    # Evaluate the model with the eval dataset.\n",
    "    score = model.evaluate(X_test,y= y_test ,steps=10, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Return the accuracy.\n",
    "\n",
    "    return score[1]\n",
    "from functools import partial\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "verbose = 1\n",
    "fit_with_partial = partial(fit_with, input_shape, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     |\n",
      "-------------------------------------\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 116s 72ms/step - loss: 1.2703 - accuracy: 0.3767\n",
      "Test loss: 0.10801259279251099\n",
      "Test accuracy: 4.716981053352356\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 4.717   \u001b[0m | \u001b[0m 0.004229\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 73ms/step - loss: 1.0698 - accuracy: 0.4284\n",
      "Test loss: 0.10224945545196533\n",
      "Test accuracy: 4.296081364154816\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 4.296   \u001b[0m | \u001b[0m 0.007231\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 125s 78ms/step - loss: 1.4472 - accuracy: 0.2416\n",
      "Test loss: 0.14132689237594603\n",
      "Test accuracy: 3.294629752635956\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 3.295   \u001b[0m | \u001b[0m 0.000101\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 73ms/step - loss: 1.1305 - accuracy: 0.4732\n",
      "Test loss: 0.09361357092857361\n",
      "Test accuracy: 5.703918933868408\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 5.704   \u001b[0m | \u001b[95m 0.003093\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 73ms/step - loss: 1.1579 - accuracy: 0.3761\n",
      "Test loss: 0.106751549243927\n",
      "Test accuracy: 5.07982611656189\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 5.08    \u001b[0m | \u001b[0m 0.001553\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 127s 79ms/step - loss: 1.1653 - accuracy: 0.3817\n",
      "Test loss: 0.10989166498184204\n",
      "Test accuracy: 3.570391833782196\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 3.57    \u001b[0m | \u001b[0m 0.001014\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 120s 75ms/step - loss: 1.1504 - accuracy: 0.3350\n",
      "Test loss: 0.10425639152526855\n",
      "Test accuracy: 3.4397676587104797\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 3.44    \u001b[0m | \u001b[0m 0.001944\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 115s 72ms/step - loss: 1.0831 - accuracy: 0.4477\n",
      "Test loss: 0.09328081011772156\n",
      "Test accuracy: 5.3410738706588745\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 5.341   \u001b[0m | \u001b[0m 0.003521\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 119s 74ms/step - loss: 1.0481 - accuracy: 0.5093\n",
      "Test loss: 0.09408735036849976\n",
      "Test accuracy: 5.181422233581543\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 5.181   \u001b[0m | \u001b[0m 0.004028\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 116s 72ms/step - loss: 1.0610 - accuracy: 0.4259\n",
      "Test loss: 0.09999374747276306\n",
      "Test accuracy: 5.1233673095703125\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 5.123   \u001b[0m | \u001b[0m 0.005434\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 74ms/step - loss: 1.0870 - accuracy: 0.4352\n",
      "Test loss: 0.09493661522865296\n",
      "Test accuracy: 5.37010133266449\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 5.37    \u001b[0m | \u001b[0m 0.002761\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 113s 70ms/step - loss: 1.0481 - accuracy: 0.4508\n",
      "Test loss: 0.09434975385665893\n",
      "Test accuracy: 5.13788104057312\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 5.138   \u001b[0m | \u001b[0m 0.006024\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 123s 76ms/step - loss: 0.9825 - accuracy: 0.4888\n",
      "Test loss: 0.08982491493225098\n",
      "Test accuracy: 5.471698045730591\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 5.472   \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 117s 73ms/step - loss: 1.0131 - accuracy: 0.4695\n",
      "Test loss: 0.09198938608169556\n",
      "Test accuracy: 5.239477753639221\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 5.239   \u001b[0m | \u001b[0m 0.00948 \u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 120s 75ms/step - loss: 1.0015 - accuracy: 0.4795\n",
      "Test loss: 0.1206917405128479\n",
      "Test accuracy: 3.526850640773773\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 3.527   \u001b[0m | \u001b[0m 0.008739\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 120s 75ms/step - loss: 1.0884 - accuracy: 0.3418\n",
      "Test loss: 0.09792449474334716\n",
      "Test accuracy: 5.500725507736206\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 5.501   \u001b[0m | \u001b[0m 0.006538\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 116s 73ms/step - loss: 1.0650 - accuracy: 0.3910\n",
      "Test loss: 0.0906749963760376\n",
      "Test accuracy: 5.326560139656067\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 5.327   \u001b[0m | \u001b[0m 0.004927\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 74ms/step - loss: 1.1015 - accuracy: 0.4284\n",
      "Test loss: 0.09757402539253235\n",
      "Test accuracy: 5.195935964584351\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 5.196   \u001b[0m | \u001b[0m 0.007925\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 115s 72ms/step - loss: 1.1517 - accuracy: 0.3711\n",
      "Test loss: 0.10731278657913208\n",
      "Test accuracy: 3.889695107936859\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 3.89    \u001b[0m | \u001b[0m 0.003107\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 114s 71ms/step - loss: 1.0671 - accuracy: 0.3979\n",
      "Test loss: 0.09564208984375\n",
      "Test accuracy: 5.3410738706588745\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 5.341   \u001b[0m | \u001b[0m 0.003081\u001b[0m |\n",
      "=====================================\n",
      "Iteration 0: \n",
      "\t{'target': 4.716981053352356, 'params': {'lr': 0.004228517846555483}}\n",
      "Iteration 1: \n",
      "\t{'target': 4.296081364154816, 'params': {'lr': 0.007231212485077366}}\n",
      "Iteration 2: \n",
      "\t{'target': 3.294629752635956, 'params': {'lr': 0.00010113231069171439}}\n",
      "Iteration 3: \n",
      "\t{'target': 5.703918933868408, 'params': {'lr': 0.003093092469055214}}\n",
      "Iteration 4: \n",
      "\t{'target': 5.07982611656189, 'params': {'lr': 0.0015528833190894193}}\n",
      "Iteration 5: \n",
      "\t{'target': 3.570391833782196, 'params': {'lr': 0.0010141520882110983}}\n",
      "Iteration 6: \n",
      "\t{'target': 3.4397676587104797, 'params': {'lr': 0.0019439760926389421}}\n",
      "Iteration 7: \n",
      "\t{'target': 5.3410738706588745, 'params': {'lr': 0.003521051197726173}}\n",
      "Iteration 8: \n",
      "\t{'target': 5.181422233581543, 'params': {'lr': 0.004027997994883633}}\n",
      "Iteration 9: \n",
      "\t{'target': 5.1233673095703125, 'params': {'lr': 0.005434285666633234}}\n",
      "Iteration 10: \n",
      "\t{'target': 5.37010133266449, 'params': {'lr': 0.002761237786148106}}\n",
      "Iteration 11: \n",
      "\t{'target': 5.13788104057312, 'params': {'lr': 0.006024380690034502}}\n",
      "Iteration 12: \n",
      "\t{'target': 5.471698045730591, 'params': {'lr': 0.01}}\n",
      "Iteration 13: \n",
      "\t{'target': 5.239477753639221, 'params': {'lr': 0.009480329785707536}}\n",
      "Iteration 14: \n",
      "\t{'target': 3.526850640773773, 'params': {'lr': 0.008738926243592307}}\n",
      "Iteration 15: \n",
      "\t{'target': 5.500725507736206, 'params': {'lr': 0.00653820192570272}}\n",
      "Iteration 16: \n",
      "\t{'target': 5.326560139656067, 'params': {'lr': 0.0049274385191790645}}\n",
      "Iteration 17: \n",
      "\t{'target': 5.195935964584351, 'params': {'lr': 0.007924726935973153}}\n",
      "Iteration 18: \n",
      "\t{'target': 3.889695107936859, 'params': {'lr': 0.0031069541240735595}}\n",
      "Iteration 19: \n",
      "\t{'target': 5.3410738706588745, 'params': {'lr': 0.0030806776442324412}}\n",
      "{'target': 5.703918933868408, 'params': {'lr': 0.003093092469055214}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'lr': (1e-4, 1e-2)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=10)\n",
    "\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_39 (Masking)         (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 24,180\n",
      "Trainable params: 24,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(Glob)\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.003, rho = 0.9), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1606 samples, validate on 689 samples\n",
      "Epoch 1/30\n",
      " - 89s - loss: 1.1655 - acc: 0.4776 - val_loss: 0.9793 - val_acc: 0.5544\n",
      "Epoch 2/30\n",
      " - 86s - loss: 0.9319 - acc: 0.5367 - val_loss: 0.9106 - val_acc: 0.5530\n",
      "Epoch 3/30\n",
      " - 84s - loss: 0.8801 - acc: 0.5411 - val_loss: 0.8682 - val_acc: 0.5559\n",
      "Epoch 4/30\n",
      " - 84s - loss: 0.8536 - acc: 0.5641 - val_loss: 0.8536 - val_acc: 0.5820\n",
      "Epoch 5/30\n",
      " - 85s - loss: 0.8376 - acc: 0.5685 - val_loss: 0.8441 - val_acc: 0.6009\n",
      "Epoch 6/30\n",
      " - 84s - loss: 0.8714 - acc: 0.5585 - val_loss: 0.8209 - val_acc: 0.6023\n",
      "Epoch 7/30\n",
      " - 84s - loss: 0.8212 - acc: 0.5722 - val_loss: 0.8203 - val_acc: 0.6038\n",
      "Epoch 8/30\n",
      " - 85s - loss: 0.8188 - acc: 0.5697 - val_loss: 0.8215 - val_acc: 0.6067\n",
      "Epoch 9/30\n",
      " - 85s - loss: 0.8119 - acc: 0.5685 - val_loss: 0.8360 - val_acc: 0.5922\n",
      "Epoch 10/30\n",
      " - 85s - loss: 0.8087 - acc: 0.5716 - val_loss: 0.8292 - val_acc: 0.6009\n",
      "Epoch 11/30\n",
      " - 82s - loss: 0.8017 - acc: 0.5766 - val_loss: 0.8456 - val_acc: 0.5965\n",
      "Epoch 12/30\n",
      " - 84s - loss: 0.8086 - acc: 0.5828 - val_loss: 0.8301 - val_acc: 0.6038\n",
      "Epoch 13/30\n",
      " - 92s - loss: 0.7960 - acc: 0.5685 - val_loss: 0.8344 - val_acc: 0.5994\n",
      "Epoch 14/30\n",
      " - 84s - loss: 0.7975 - acc: 0.5741 - val_loss: 0.8773 - val_acc: 0.5907\n",
      "Epoch 15/30\n",
      " - 87s - loss: 0.7923 - acc: 0.5946 - val_loss: 0.8492 - val_acc: 0.5951\n",
      "Epoch 16/30\n",
      " - 87s - loss: 0.7884 - acc: 0.6083 - val_loss: 0.8231 - val_acc: 0.6096\n",
      "Epoch 17/30\n",
      " - 88s - loss: 0.7803 - acc: 0.6027 - val_loss: 0.9211 - val_acc: 0.5776\n",
      "Epoch 18/30\n",
      " - 86s - loss: 0.7748 - acc: 0.6077 - val_loss: 0.8457 - val_acc: 0.6052\n",
      "Epoch 19/30\n",
      " - 86s - loss: 0.7713 - acc: 0.6127 - val_loss: 0.8557 - val_acc: 0.5864\n",
      "Epoch 20/30\n",
      " - 99s - loss: 0.7606 - acc: 0.6208 - val_loss: 0.8631 - val_acc: 0.5893\n",
      "Epoch 21/30\n",
      " - 110s - loss: 0.7584 - acc: 0.6146 - val_loss: 0.8069 - val_acc: 0.6023\n",
      "Epoch 22/30\n",
      " - 89s - loss: 0.7587 - acc: 0.6214 - val_loss: 0.8132 - val_acc: 0.6038\n",
      "Epoch 23/30\n",
      " - 89s - loss: 0.7556 - acc: 0.6164 - val_loss: 0.8330 - val_acc: 0.5864\n",
      "Epoch 24/30\n",
      " - 88s - loss: 0.7445 - acc: 0.6127 - val_loss: 0.8440 - val_acc: 0.5878\n",
      "Epoch 25/30\n",
      " - 84s - loss: 0.7464 - acc: 0.6239 - val_loss: 0.8955 - val_acc: 0.5922\n",
      "Epoch 26/30\n",
      " - 92s - loss: 0.7434 - acc: 0.6108 - val_loss: 0.8977 - val_acc: 0.5820\n",
      "Epoch 27/30\n",
      " - 83s - loss: 0.7398 - acc: 0.6308 - val_loss: 0.8364 - val_acc: 0.6139\n",
      "Epoch 28/30\n",
      " - 88s - loss: 0.7356 - acc: 0.6320 - val_loss: 0.8809 - val_acc: 0.5907\n",
      "Epoch 29/30\n",
      " - 87s - loss: 0.7250 - acc: 0.6382 - val_loss: 0.8602 - val_acc: 0.6009\n",
      "Epoch 30/30\n",
      " - 87s - loss: 0.7301 - acc: 0.6270 - val_loss: 0.8440 - val_acc: 0.6023\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=100, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1606, 5000, 19)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   varible_name  perturbation_effect\n",
      "17      컴퓨터/인터넷             0.105500\n",
      "6            기타             0.067070\n",
      "9       비즈니스/쇼핑             0.064833\n",
      "0    세션당 방문사이트수             0.037320\n",
      "7        뉴스/미디어             0.025902\n",
      "1        세션지속시간             0.016763\n",
      "8         문화/예술             0.014035\n",
      "3            게임             0.005174\n",
      "11       스포츠/레저             0.005075\n",
      "15        정치/사회             0.002527\n",
      "10        생활/건강             0.002033\n",
      "2     쇼핑사이트방문여부             0.001977\n",
      "5         교육/학교             0.001861\n",
      "4        경제/재테크             0.001658\n",
      "13        연예/오락             0.000948\n",
      "18        학문/사전             0.000616\n",
      "14           인물             0.000532\n",
      "12      여행/세계정보             0.000301\n",
      "16           종교             0.000023\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(X_train.reshape(1606*5000, 19))\n",
    "train_df.columns = ['세션당 방문사이트수','세션지속시간','쇼핑사이트방문여부' ,\n",
    "                    '게임', '경제/재테크', '교육/학교', '기타', '뉴스/미디어', '문화/예술', '비즈니스/쇼핑', '생활/건강', '스포츠/레저',\n",
    " '여행/세계정보', '연예/오락', '인물', '정치/사회', '종교', '컴퓨터/인터넷', '학문/사전']\n",
    "## Sensitivity Analysis\n",
    "importance_df = pd.DataFrame(np.zeros((19, 2)), columns=['varible_name', 'perturbation_effect'])\n",
    "def var_importance(model):\n",
    "    x = X_test # Get a sample of data\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(19):  # iterate over the three features\n",
    "        new_x = x.copy()\n",
    "        perturbation = np.random.normal(0.0, 0.2, size=new_x.shape[:2])\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5 #RMSE\n",
    "        importance_df.iloc[i,0] = train_df.columns[i]\n",
    "        importance_df.iloc[i,1] = effect\n",
    "        #print(f'Variable {i+1}, perturbation effect: {effect:.4f}')\n",
    "var_importance(model)\n",
    "importance_df = importance_df.sort_values(by='perturbation_effect', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perm = PermutationImportance(model, random_state=1).fit(X_test,y_test)\n",
    "#eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6023222208023071\n"
     ]
    }
   ],
   "source": [
    "#가전제품 f1-score: 0.7819220343082984\n",
    "#패션 accuracy: 0.7188029361269287\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가전제품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_가전제품_resampled, Y_가전제품_resampled, test_size=0.3, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#쇼핑사이트 방문횟수, 문화/예술, 비즈니스/쇼핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_41 (Masking)         (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 24,180\n",
      "Trainable params: 24,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(Glob)\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2455 samples, validate on 1053 samples\n",
      "Epoch 1/50\n",
      " - 38s - loss: 1.3801 - acc: 0.2684 - val_loss: 1.3589 - val_acc: 0.3628\n",
      "Epoch 2/50\n",
      " - 37s - loss: 1.3469 - acc: 0.4012 - val_loss: 1.3279 - val_acc: 0.4520\n",
      "Epoch 3/50\n",
      " - 36s - loss: 1.3215 - acc: 0.4224 - val_loss: 1.2981 - val_acc: 0.4587\n",
      "Epoch 4/50\n",
      " - 36s - loss: 1.2964 - acc: 0.4456 - val_loss: 1.2744 - val_acc: 0.4653\n",
      "Epoch 5/50\n",
      " - 36s - loss: 1.2615 - acc: 0.4648 - val_loss: 1.2259 - val_acc: 0.4995\n",
      "Epoch 6/50\n",
      " - 36s - loss: 1.2211 - acc: 0.4900 - val_loss: 1.1845 - val_acc: 0.5043\n",
      "Epoch 7/50\n",
      " - 36s - loss: 1.1796 - acc: 0.4982 - val_loss: 1.1478 - val_acc: 0.4938\n",
      "Epoch 8/50\n",
      " - 36s - loss: 1.1479 - acc: 0.4941 - val_loss: 1.1309 - val_acc: 0.5062\n",
      "Epoch 9/50\n",
      " - 36s - loss: 1.1204 - acc: 0.5173 - val_loss: 1.0910 - val_acc: 0.5347\n",
      "Epoch 10/50\n",
      " - 36s - loss: 1.0916 - acc: 0.5271 - val_loss: 1.0662 - val_acc: 0.5537\n",
      "Epoch 11/50\n",
      " - 36s - loss: 1.0716 - acc: 0.5397 - val_loss: 1.0472 - val_acc: 0.5698\n",
      "Epoch 12/50\n",
      " - 36s - loss: 1.0567 - acc: 0.5552 - val_loss: 1.0437 - val_acc: 0.5423\n",
      "Epoch 13/50\n",
      " - 36s - loss: 1.0410 - acc: 0.5560 - val_loss: 1.0174 - val_acc: 0.5622\n",
      "Epoch 14/50\n",
      " - 36s - loss: 1.0225 - acc: 0.5650 - val_loss: 1.0114 - val_acc: 0.5670\n",
      "Epoch 15/50\n",
      " - 36s - loss: 1.0309 - acc: 0.5532 - val_loss: 1.0438 - val_acc: 0.5489\n",
      "Epoch 16/50\n",
      " - 36s - loss: 1.0171 - acc: 0.5674 - val_loss: 0.9921 - val_acc: 0.5670\n",
      "Epoch 17/50\n",
      " - 36s - loss: 0.9910 - acc: 0.5804 - val_loss: 0.9845 - val_acc: 0.5679\n",
      "Epoch 18/50\n",
      " - 37s - loss: 0.9805 - acc: 0.5866 - val_loss: 0.9925 - val_acc: 0.5708\n",
      "Epoch 19/50\n",
      " - 36s - loss: 0.9819 - acc: 0.5829 - val_loss: 0.9717 - val_acc: 0.5783\n",
      "Epoch 20/50\n",
      " - 36s - loss: 0.9610 - acc: 0.5988 - val_loss: 0.9719 - val_acc: 0.5831\n",
      "Epoch 21/50\n",
      " - 36s - loss: 0.9694 - acc: 0.5849 - val_loss: 0.9643 - val_acc: 0.5954\n",
      "Epoch 22/50\n",
      " - 36s - loss: 0.9758 - acc: 0.5882 - val_loss: 0.9670 - val_acc: 0.5802\n",
      "Epoch 23/50\n",
      " - 36s - loss: 0.9567 - acc: 0.5992 - val_loss: 0.9604 - val_acc: 0.5945\n",
      "Epoch 24/50\n",
      " - 36s - loss: 0.9515 - acc: 0.6020 - val_loss: 0.9618 - val_acc: 0.5793\n",
      "Epoch 25/50\n",
      " - 35s - loss: 0.9432 - acc: 0.6077 - val_loss: 0.9600 - val_acc: 0.5812\n",
      "Epoch 26/50\n",
      " - 36s - loss: 0.9361 - acc: 0.6098 - val_loss: 0.9510 - val_acc: 0.6049\n",
      "Epoch 27/50\n",
      " - 36s - loss: 0.9405 - acc: 0.6065 - val_loss: 0.9656 - val_acc: 0.5850\n",
      "Epoch 28/50\n",
      " - 36s - loss: 0.9286 - acc: 0.6138 - val_loss: 0.9580 - val_acc: 0.5840\n",
      "Epoch 29/50\n",
      " - 36s - loss: 0.9246 - acc: 0.6151 - val_loss: 0.9631 - val_acc: 0.5850\n",
      "Epoch 30/50\n",
      " - 36s - loss: 0.9407 - acc: 0.6029 - val_loss: 0.9349 - val_acc: 0.6116\n",
      "Epoch 31/50\n",
      " - 36s - loss: 0.9106 - acc: 0.6281 - val_loss: 0.9337 - val_acc: 0.6182\n",
      "Epoch 32/50\n",
      " - 36s - loss: 0.9082 - acc: 0.6240 - val_loss: 0.9483 - val_acc: 0.5973\n",
      "Epoch 33/50\n",
      " - 37s - loss: 0.9032 - acc: 0.6289 - val_loss: 0.9581 - val_acc: 0.5935\n",
      "Epoch 34/50\n",
      " - 36s - loss: 0.8947 - acc: 0.6301 - val_loss: 0.9298 - val_acc: 0.6116\n",
      "Epoch 35/50\n",
      " - 36s - loss: 0.8947 - acc: 0.6273 - val_loss: 0.9754 - val_acc: 0.5850\n",
      "Epoch 36/50\n",
      " - 36s - loss: 0.8914 - acc: 0.6273 - val_loss: 0.9211 - val_acc: 0.6211\n",
      "Epoch 37/50\n",
      " - 36s - loss: 0.8863 - acc: 0.6281 - val_loss: 0.9883 - val_acc: 0.5821\n",
      "Epoch 38/50\n",
      " - 36s - loss: 0.8905 - acc: 0.6265 - val_loss: 0.9251 - val_acc: 0.6144\n",
      "Epoch 39/50\n",
      " - 36s - loss: 0.8889 - acc: 0.6253 - val_loss: 0.9502 - val_acc: 0.5954\n",
      "Epoch 40/50\n",
      " - 36s - loss: 0.8797 - acc: 0.6363 - val_loss: 0.9175 - val_acc: 0.6268\n",
      "Epoch 41/50\n",
      " - 36s - loss: 0.8711 - acc: 0.6391 - val_loss: 0.9223 - val_acc: 0.6154\n",
      "Epoch 42/50\n",
      " - 36s - loss: 0.8774 - acc: 0.6281 - val_loss: 0.9786 - val_acc: 0.5945\n",
      "Epoch 43/50\n",
      " - 37s - loss: 0.8783 - acc: 0.6379 - val_loss: 0.9050 - val_acc: 0.6182\n",
      "Epoch 44/50\n",
      " - 36s - loss: 0.8555 - acc: 0.6481 - val_loss: 0.9199 - val_acc: 0.6106\n",
      "Epoch 45/50\n",
      " - 36s - loss: 0.8493 - acc: 0.6517 - val_loss: 0.8942 - val_acc: 0.6439\n",
      "Epoch 46/50\n",
      " - 36s - loss: 0.8505 - acc: 0.6505 - val_loss: 0.9747 - val_acc: 0.6059\n",
      "Epoch 47/50\n",
      " - 37s - loss: 0.8509 - acc: 0.6505 - val_loss: 0.8874 - val_acc: 0.6315\n",
      "Epoch 48/50\n",
      " - 36s - loss: 0.8377 - acc: 0.6591 - val_loss: 0.8904 - val_acc: 0.6401\n",
      "Epoch 49/50\n",
      " - 35s - loss: 0.8338 - acc: 0.6546 - val_loss: 0.9086 - val_acc: 0.6372\n",
      "Epoch 50/50\n",
      " - 35s - loss: 0.8375 - acc: 0.6542 - val_loss: 0.8897 - val_acc: 0.6325\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=200, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2455, 5000, 19)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   varible_name  perturbation_effect\n",
      "6            기타             0.019017\n",
      "0    세션당 방문사이트수             0.018900\n",
      "9       비즈니스/쇼핑             0.017860\n",
      "17      컴퓨터/인터넷             0.011322\n",
      "1        세션지속시간             0.005882\n",
      "3            게임             0.004853\n",
      "2     쇼핑사이트방문여부             0.002543\n",
      "7        뉴스/미디어             0.002450\n",
      "15        정치/사회             0.002309\n",
      "5         교육/학교             0.001170\n",
      "4        경제/재테크             0.000860\n",
      "16           종교             0.000262\n",
      "11       스포츠/레저             0.000238\n",
      "10        생활/건강             0.000212\n",
      "12      여행/세계정보             0.000210\n",
      "18        학문/사전             0.000137\n",
      "13        연예/오락             0.000118\n",
      "8         문화/예술             0.000115\n",
      "14           인물             0.000049\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(X_train.reshape(X_train.shape[0] * X_train.shape[1], 19))\n",
    "train_df.columns = ['세션당 방문사이트수','세션지속시간','쇼핑사이트방문여부' ,\n",
    "                    '게임', '경제/재테크', '교육/학교', '기타', '뉴스/미디어', '문화/예술', '비즈니스/쇼핑', '생활/건강', '스포츠/레저',\n",
    " '여행/세계정보', '연예/오락', '인물', '정치/사회', '종교', '컴퓨터/인터넷', '학문/사전']\n",
    "\n",
    "## Sensitivity Analysis\n",
    "importance_df = pd.DataFrame(np.zeros((19, 2)), columns=['varible_name', 'perturbation_effect'])\n",
    "def var_importance(model):\n",
    "    x = X_test # Get a sample of data\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(19):  # iterate over the three features\n",
    "        new_x = x.copy()\n",
    "        perturbation = np.random.normal(0.0, 0.2, size=new_x.shape[:2])\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5 #RMSE\n",
    "        importance_df.iloc[i,0] = train_df.columns[i]\n",
    "        importance_df.iloc[i,1] = effect\n",
    "        #print(f'Variable {i+1}, perturbation effect: {effect:.4f}')\n",
    "var_importance(model)\n",
    "importance_df = importance_df.sort_values(by='perturbation_effect', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()                                       \n",
    "plt.show()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632478654384613\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 화장품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_화장품_resampled, Y_화장품_resampled, test_size=0.3, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_42 (Masking)         (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 24,180\n",
      "Trainable params: 24,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1732 samples, validate on 743 samples\n",
      "Epoch 1/60\n",
      " - 28s - loss: 1.4262 - acc: 0.1940 - val_loss: 1.3567 - val_acc: 0.3782\n",
      "Epoch 2/60\n",
      " - 27s - loss: 1.3487 - acc: 0.3597 - val_loss: 1.3113 - val_acc: 0.3432\n",
      "Epoch 3/60\n",
      " - 27s - loss: 1.3087 - acc: 0.3886 - val_loss: 1.2749 - val_acc: 0.4065\n",
      "Epoch 4/60\n",
      " - 27s - loss: 1.2751 - acc: 0.4203 - val_loss: 1.2483 - val_acc: 0.4509\n",
      "Epoch 5/60\n",
      " - 27s - loss: 1.2504 - acc: 0.4434 - val_loss: 1.2251 - val_acc: 0.4711\n",
      "Epoch 6/60\n",
      " - 27s - loss: 1.2308 - acc: 0.4567 - val_loss: 1.2054 - val_acc: 0.4764\n",
      "Epoch 7/60\n",
      " - 27s - loss: 1.2090 - acc: 0.4521 - val_loss: 1.1852 - val_acc: 0.4778\n",
      "Epoch 8/60\n",
      " - 27s - loss: 1.1909 - acc: 0.4544 - val_loss: 1.1623 - val_acc: 0.4926\n",
      "Epoch 9/60\n",
      " - 27s - loss: 1.1592 - acc: 0.4769 - val_loss: 1.1369 - val_acc: 0.5034\n",
      "Epoch 10/60\n",
      " - 26s - loss: 1.1455 - acc: 0.4630 - val_loss: 1.1173 - val_acc: 0.5128\n",
      "Epoch 11/60\n",
      " - 27s - loss: 1.1214 - acc: 0.4902 - val_loss: 1.0938 - val_acc: 0.5168\n",
      "Epoch 12/60\n",
      " - 27s - loss: 1.1012 - acc: 0.4925 - val_loss: 1.0712 - val_acc: 0.5316\n",
      "Epoch 13/60\n",
      " - 27s - loss: 1.0820 - acc: 0.5000 - val_loss: 1.0432 - val_acc: 0.5437\n",
      "Epoch 14/60\n",
      " - 27s - loss: 1.0520 - acc: 0.5064 - val_loss: 1.0058 - val_acc: 0.5612\n",
      "Epoch 15/60\n",
      " - 27s - loss: 1.0217 - acc: 0.5277 - val_loss: 0.9681 - val_acc: 0.5760\n",
      "Epoch 16/60\n",
      " - 26s - loss: 1.0010 - acc: 0.5196 - val_loss: 0.9400 - val_acc: 0.5814\n",
      "Epoch 17/60\n",
      " - 27s - loss: 0.9698 - acc: 0.5393 - val_loss: 0.9064 - val_acc: 0.5855\n",
      "Epoch 18/60\n",
      " - 27s - loss: 0.9580 - acc: 0.5502 - val_loss: 0.8908 - val_acc: 0.5949\n",
      "Epoch 19/60\n",
      " - 26s - loss: 0.9179 - acc: 0.5722 - val_loss: 0.8631 - val_acc: 0.6110\n",
      "Epoch 20/60\n",
      " - 26s - loss: 0.9048 - acc: 0.5699 - val_loss: 0.8441 - val_acc: 0.6097\n",
      "Epoch 21/60\n",
      " - 27s - loss: 0.8817 - acc: 0.5878 - val_loss: 0.8293 - val_acc: 0.6164\n",
      "Epoch 22/60\n",
      " - 27s - loss: 0.8843 - acc: 0.5826 - val_loss: 0.8268 - val_acc: 0.6030\n",
      "Epoch 23/60\n",
      " - 27s - loss: 0.8568 - acc: 0.6045 - val_loss: 0.8085 - val_acc: 0.6043\n",
      "Epoch 24/60\n",
      " - 26s - loss: 0.8493 - acc: 0.5924 - val_loss: 0.7942 - val_acc: 0.6191\n",
      "Epoch 25/60\n",
      " - 27s - loss: 0.8374 - acc: 0.6016 - val_loss: 0.8085 - val_acc: 0.5962\n",
      "Epoch 26/60\n",
      " - 27s - loss: 0.8453 - acc: 0.6028 - val_loss: 0.7886 - val_acc: 0.6164\n",
      "Epoch 27/60\n",
      " - 26s - loss: 0.8330 - acc: 0.5930 - val_loss: 0.7864 - val_acc: 0.6299\n",
      "Epoch 28/60\n",
      " - 27s - loss: 0.8275 - acc: 0.6016 - val_loss: 0.7867 - val_acc: 0.6231\n",
      "Epoch 29/60\n",
      " - 27s - loss: 0.8200 - acc: 0.5947 - val_loss: 0.7813 - val_acc: 0.6272\n",
      "Epoch 30/60\n",
      " - 27s - loss: 0.8126 - acc: 0.6039 - val_loss: 0.7758 - val_acc: 0.6231\n",
      "Epoch 31/60\n",
      " - 27s - loss: 0.8204 - acc: 0.5941 - val_loss: 0.7795 - val_acc: 0.6083\n",
      "Epoch 32/60\n",
      " - 27s - loss: 0.7887 - acc: 0.6109 - val_loss: 0.7757 - val_acc: 0.6124\n",
      "Epoch 33/60\n",
      " - 27s - loss: 0.7973 - acc: 0.6022 - val_loss: 0.7798 - val_acc: 0.6124\n",
      "Epoch 34/60\n",
      " - 26s - loss: 0.7856 - acc: 0.6062 - val_loss: 0.7726 - val_acc: 0.6191\n",
      "Epoch 35/60\n",
      " - 27s - loss: 0.7978 - acc: 0.6045 - val_loss: 0.7748 - val_acc: 0.6218\n",
      "Epoch 36/60\n",
      " - 27s - loss: 0.7854 - acc: 0.6085 - val_loss: 0.7686 - val_acc: 0.6178\n",
      "Epoch 37/60\n",
      " - 27s - loss: 0.7838 - acc: 0.6120 - val_loss: 0.7715 - val_acc: 0.6312\n",
      "Epoch 38/60\n",
      " - 26s - loss: 0.7985 - acc: 0.5999 - val_loss: 0.7739 - val_acc: 0.6231\n",
      "Epoch 39/60\n",
      " - 27s - loss: 0.7736 - acc: 0.6172 - val_loss: 0.8437 - val_acc: 0.5868\n",
      "Epoch 40/60\n",
      " - 27s - loss: 0.8068 - acc: 0.5958 - val_loss: 0.7673 - val_acc: 0.6218\n",
      "Epoch 41/60\n",
      " - 27s - loss: 0.7718 - acc: 0.6189 - val_loss: 0.7646 - val_acc: 0.6299\n",
      "Epoch 42/60\n",
      " - 27s - loss: 0.7678 - acc: 0.6334 - val_loss: 0.7672 - val_acc: 0.6205\n",
      "Epoch 43/60\n",
      " - 27s - loss: 0.7569 - acc: 0.6357 - val_loss: 0.7712 - val_acc: 0.6218\n",
      "Epoch 44/60\n",
      " - 27s - loss: 0.8019 - acc: 0.6189 - val_loss: 0.7660 - val_acc: 0.6205\n",
      "Epoch 45/60\n",
      " - 27s - loss: 0.7586 - acc: 0.6241 - val_loss: 0.7628 - val_acc: 0.6231\n",
      "Epoch 46/60\n",
      " - 27s - loss: 0.7674 - acc: 0.6264 - val_loss: 0.7687 - val_acc: 0.6218\n",
      "Epoch 47/60\n",
      " - 27s - loss: 0.7554 - acc: 0.6357 - val_loss: 0.7575 - val_acc: 0.6380\n",
      "Epoch 48/60\n",
      " - 27s - loss: 0.7554 - acc: 0.6247 - val_loss: 0.7578 - val_acc: 0.6339\n",
      "Epoch 49/60\n",
      " - 27s - loss: 0.7501 - acc: 0.6345 - val_loss: 0.7562 - val_acc: 0.6366\n",
      "Epoch 50/60\n",
      " - 26s - loss: 0.7687 - acc: 0.6391 - val_loss: 0.7699 - val_acc: 0.6231\n",
      "Epoch 51/60\n",
      " - 27s - loss: 0.7539 - acc: 0.6305 - val_loss: 0.7560 - val_acc: 0.6272\n",
      "Epoch 52/60\n",
      " - 26s - loss: 0.7509 - acc: 0.6357 - val_loss: 0.7658 - val_acc: 0.6285\n",
      "Epoch 53/60\n",
      " - 27s - loss: 0.7573 - acc: 0.6305 - val_loss: 0.7751 - val_acc: 0.6151\n",
      "Epoch 54/60\n",
      " - 27s - loss: 0.7457 - acc: 0.6438 - val_loss: 0.7730 - val_acc: 0.6393\n",
      "Epoch 55/60\n",
      " - 27s - loss: 0.7497 - acc: 0.6415 - val_loss: 0.7673 - val_acc: 0.6299\n",
      "Epoch 56/60\n",
      " - 27s - loss: 0.7435 - acc: 0.6363 - val_loss: 0.7564 - val_acc: 0.6339\n",
      "Epoch 57/60\n",
      " - 26s - loss: 0.8203 - acc: 0.6016 - val_loss: 0.7572 - val_acc: 0.6231\n",
      "Epoch 58/60\n",
      " - 27s - loss: 0.7632 - acc: 0.6334 - val_loss: 0.7468 - val_acc: 0.6339\n",
      "Epoch 59/60\n",
      " - 27s - loss: 0.7345 - acc: 0.6357 - val_loss: 0.7485 - val_acc: 0.6433\n",
      "Epoch 60/60\n",
      " - 27s - loss: 0.7372 - acc: 0.6467 - val_loss: 0.7515 - val_acc: 0.6433\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=60, batch_size=500, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   varible_name  perturbation_effect\n",
      "17      컴퓨터/인터넷             0.049682\n",
      "9       비즈니스/쇼핑             0.042533\n",
      "6            기타             0.042316\n",
      "0    세션당 방문사이트수             0.039831\n",
      "2     쇼핑사이트방문여부             0.024230\n",
      "8         문화/예술             0.018970\n",
      "3            게임             0.016526\n",
      "14           인물             0.007616\n",
      "7        뉴스/미디어             0.006994\n",
      "1        세션지속시간             0.005104\n",
      "15        정치/사회             0.002732\n",
      "18        학문/사전             0.001604\n",
      "4        경제/재테크             0.000867\n",
      "5         교육/학교             0.000790\n",
      "10        생활/건강             0.000526\n",
      "11       스포츠/레저             0.000358\n",
      "13        연예/오락             0.000333\n",
      "12      여행/세계정보             0.000140\n",
      "16           종교             0.000001\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(X_train.reshape(X_train.shape[0] * X_train.shape[1], 19))\n",
    "train_df.columns = ['세션당 방문사이트수','세션지속시간','쇼핑사이트방문여부' ,\n",
    "                    '게임', '경제/재테크', '교육/학교', '기타', '뉴스/미디어', '문화/예술', '비즈니스/쇼핑', '생활/건강', '스포츠/레저',\n",
    " '여행/세계정보', '연예/오락', '인물', '정치/사회', '종교', '컴퓨터/인터넷', '학문/사전']\n",
    "## Sensitivity Analysis\n",
    "importance_df = pd.DataFrame(np.zeros((19, 2)), columns=['varible_name', 'perturbation_effect'])\n",
    "def var_importance(model):\n",
    "    x = X_test # Get a sample of data\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(19):  # iterate over the three features\n",
    "        new_x = x.copy()\n",
    "        perturbation = np.random.normal(0.0, 0.2, size=new_x.shape[:2])\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5 #RMSE\n",
    "        importance_df.iloc[i,0] = train_df.columns[i]\n",
    "        importance_df.iloc[i,1] = effect\n",
    "        #print(f'Variable {i+1}, perturbation effect: {effect:.4f}')\n",
    "var_importance(model)\n",
    "importance_df = importance_df.sort_values(by='perturbation_effect', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()                                       \n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
