{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tqdm import tqdm_notebook\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.utils import to_categorical\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3772967992060511356\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3641012722422981035\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1902627009851827314\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5811535872\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1384053580184476157\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.6/dist-packages (1.0.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.1)\r\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_초순_패션 = pd.read_csv('RecoSystem/data/Y_초순_패션.csv')\n",
    "Y_중순_패션 = pd.read_csv('RecoSystem/data/Y_중순_패션.csv')\n",
    "Y_하순_패션 = pd.read_csv('RecoSystem/data/Y_하순_패션.csv')\n",
    "\n",
    "Y_초순_화장품 = pd.read_csv('RecoSystem/data/Y_초순_화장품.csv')\n",
    "Y_중순_화장품 = pd.read_csv('RecoSystem/data/Y_중순_화장품.csv')\n",
    "Y_하순_화장품 = pd.read_csv('RecoSystem/data/Y_하순_화장품.csv')\n",
    "\n",
    "Y_초순_가전제품 = pd.read_csv('RecoSystem/data/Y_초순_가전제품.csv')\n",
    "Y_중순_가전제품 = pd.read_csv('RecoSystem/data/Y_중순_가전제품.csv')\n",
    "Y_하순_가전제품 = pd.read_csv('RecoSystem/data/Y_하순_가전제품.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    991\n",
       "1     47\n",
       "Name: 가전제품구매, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_초순_가전제품['가전제품구매'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_초순_패션 = pd.read_csv('RecoSystem/data/초순_패션_3d_array.csv')\n",
    "X_중순_패션 = pd.read_csv('RecoSystem/data/중순_패션_3d_array.csv')\n",
    "X_하순_패션 = pd.read_csv('RecoSystem/data/하순_패션_3d_array.csv')\n",
    "\n",
    "X_초순_화장품 = pd.read_csv('RecoSystem/data/초순_화장품_3d_array.csv')\n",
    "X_중순_화장품 = pd.read_csv('RecoSystem/data/중순_화장품_3d_array.csv')\n",
    "X_하순_화장품 = pd.read_csv('RecoSystem/data/하순_화장품_3d_array.csv')\n",
    "\n",
    "X_초순_가전제품 = pd.read_csv('RecoSystem/data/초순_가전제품_3d_array.csv')\n",
    "X_중순_가전제품 = pd.read_csv('RecoSystem/data/중순_가전제품_3d_array.csv')\n",
    "X_하순_가전제품 = pd.read_csv('RecoSystem/data/하순_가전제품_3d_array.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94990</th>\n",
       "      <th>94991</th>\n",
       "      <th>94992</th>\n",
       "      <th>94993</th>\n",
       "      <th>94994</th>\n",
       "      <th>94995</th>\n",
       "      <th>94996</th>\n",
       "      <th>94997</th>\n",
       "      <th>94998</th>\n",
       "      <th>94999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  94990  94991  94992  94993  94994  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...      1      0      0      0      0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "\n",
       "   94995  94996  94997  94998  94999  \n",
       "0      0      0      0      0      0  \n",
       "1      0      0      0      1      0  \n",
       "2      0      0      0      0      0  \n",
       "3      0      0      0      0      0  \n",
       "4      0      0      0      1      0  \n",
       "\n",
       "[5 rows x 95000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_초순_가전제품.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_초순_가전제품 = np.asarray(X_초순_가전제품)\n",
    "X_중순_가전제품 = np.asarray(X_중순_가전제품)\n",
    "X_하순_가전제품 = np.asarray(X_하순_가전제품)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_초순_가전제품 = np.asarray(Y_초순_가전제품.iloc[:, 1:])\n",
    "Y_중순_가전제품 = np.asarray(Y_중순_가전제품.iloc[:, 1:])\n",
    "Y_하순_가전제품 = np.asarray(Y_하순_가전제품.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_초순_가전제품 = X_초순_가전제품.reshape(-1, 5000, 19)\n",
    "X_중순_가전제품 = X_중순_가전제품.reshape(-1, 5000, 19)\n",
    "X_하순_가전제품 = X_하순_가전제품.reshape(-1, 5000, 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5000일때 자꾸 커널이 죽음\n",
    "def oversample(X, Y):\n",
    "    max_len = 5000\n",
    "    X_resampled, Y_resampled = smote.fit_resample(X, Y)\n",
    "    X_resampled = X_resampled.reshape(X_resampled.shape[0], max_len, int(X_resampled.shape[1]/max_len))\n",
    "    return X_resampled, Y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_초순_가전제품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-73bdf17f99af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_초순_가전제품_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_초순_가전제품_resampled\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0moversample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_초순_가전제품\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_초순_가전제품\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_중순_가전제품_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_중순_가전제품_resampled\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0moversample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_중순_가전제품\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_중순_가전제품\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_하순_가전제품_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_하순_가전제품_resampled\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0moversample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_하순_가전제품\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_하순_가전제품\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-a0dc35e7383c>\u001b[0m in \u001b[0;36moversample\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_resampled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[1;32m     74\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 574\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "X_초순_가전제품_resampled, Y_초순_가전제품_resampled =oversample(X_초순_가전제품, Y_초순_가전제품)\n",
    "X_중순_가전제품_resampled, Y_중순_가전제품_resampled =oversample(X_중순_가전제품, Y_중순_가전제품)\n",
    "X_하순_가전제품_resampled, Y_하순_가전제품_resampled =oversample(X_하순_가전제품, Y_하순_가전제품)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 가동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 초순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_초순_가전제품, Y_초순_가전제품, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = to_categorical(y_train)\n",
    "#y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "def get_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(64,input_shape = input_shape))\n",
    "    #model.add(GlobalMaxPool1D())\n",
    "    model.add(Dense(32, activation= 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation= 'relu'))\n",
    "    model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc'])\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with(input_shape, verbose, lr):\n",
    "\n",
    "    # Create the model using a specified hyperparameters.\n",
    "    model = get_model(input_shape)\n",
    "\n",
    "    # Train the model for a specified number of epochs.\n",
    "    optimizer = RMSprop(learning_rate=lr)\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with the train dataset.\n",
    "    model.fit(x=X_train,y= y_train ,epochs=1,\n",
    "              batch_size=64, verbose=verbose)\n",
    "\n",
    "    # Evaluate the model with the eval dataset.\n",
    "    score = model.evaluate(X_test,y= y_test ,steps=10, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Return the accuracy.\n",
    "\n",
    "    return score[1]\n",
    "from functools import partial\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "verbose = 1\n",
    "fit_with_partial = partial(fit_with, input_shape, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     |\n",
      "-------------------------------------\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 116s 72ms/step - loss: 1.2703 - accuracy: 0.3767\n",
      "Test loss: 0.10801259279251099\n",
      "Test accuracy: 4.716981053352356\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 4.717   \u001b[0m | \u001b[0m 0.004229\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 73ms/step - loss: 1.0698 - accuracy: 0.4284\n",
      "Test loss: 0.10224945545196533\n",
      "Test accuracy: 4.296081364154816\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 4.296   \u001b[0m | \u001b[0m 0.007231\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 125s 78ms/step - loss: 1.4472 - accuracy: 0.2416\n",
      "Test loss: 0.14132689237594603\n",
      "Test accuracy: 3.294629752635956\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 3.295   \u001b[0m | \u001b[0m 0.000101\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 73ms/step - loss: 1.1305 - accuracy: 0.4732\n",
      "Test loss: 0.09361357092857361\n",
      "Test accuracy: 5.703918933868408\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 5.704   \u001b[0m | \u001b[95m 0.003093\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 73ms/step - loss: 1.1579 - accuracy: 0.3761\n",
      "Test loss: 0.106751549243927\n",
      "Test accuracy: 5.07982611656189\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 5.08    \u001b[0m | \u001b[0m 0.001553\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 127s 79ms/step - loss: 1.1653 - accuracy: 0.3817\n",
      "Test loss: 0.10989166498184204\n",
      "Test accuracy: 3.570391833782196\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 3.57    \u001b[0m | \u001b[0m 0.001014\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 120s 75ms/step - loss: 1.1504 - accuracy: 0.3350\n",
      "Test loss: 0.10425639152526855\n",
      "Test accuracy: 3.4397676587104797\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 3.44    \u001b[0m | \u001b[0m 0.001944\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 115s 72ms/step - loss: 1.0831 - accuracy: 0.4477\n",
      "Test loss: 0.09328081011772156\n",
      "Test accuracy: 5.3410738706588745\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 5.341   \u001b[0m | \u001b[0m 0.003521\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 119s 74ms/step - loss: 1.0481 - accuracy: 0.5093\n",
      "Test loss: 0.09408735036849976\n",
      "Test accuracy: 5.181422233581543\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 5.181   \u001b[0m | \u001b[0m 0.004028\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 116s 72ms/step - loss: 1.0610 - accuracy: 0.4259\n",
      "Test loss: 0.09999374747276306\n",
      "Test accuracy: 5.1233673095703125\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 5.123   \u001b[0m | \u001b[0m 0.005434\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 74ms/step - loss: 1.0870 - accuracy: 0.4352\n",
      "Test loss: 0.09493661522865296\n",
      "Test accuracy: 5.37010133266449\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 5.37    \u001b[0m | \u001b[0m 0.002761\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 113s 70ms/step - loss: 1.0481 - accuracy: 0.4508\n",
      "Test loss: 0.09434975385665893\n",
      "Test accuracy: 5.13788104057312\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 5.138   \u001b[0m | \u001b[0m 0.006024\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 123s 76ms/step - loss: 0.9825 - accuracy: 0.4888\n",
      "Test loss: 0.08982491493225098\n",
      "Test accuracy: 5.471698045730591\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 5.472   \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 117s 73ms/step - loss: 1.0131 - accuracy: 0.4695\n",
      "Test loss: 0.09198938608169556\n",
      "Test accuracy: 5.239477753639221\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 5.239   \u001b[0m | \u001b[0m 0.00948 \u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 120s 75ms/step - loss: 1.0015 - accuracy: 0.4795\n",
      "Test loss: 0.1206917405128479\n",
      "Test accuracy: 3.526850640773773\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 3.527   \u001b[0m | \u001b[0m 0.008739\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 120s 75ms/step - loss: 1.0884 - accuracy: 0.3418\n",
      "Test loss: 0.09792449474334716\n",
      "Test accuracy: 5.500725507736206\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 5.501   \u001b[0m | \u001b[0m 0.006538\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 116s 73ms/step - loss: 1.0650 - accuracy: 0.3910\n",
      "Test loss: 0.0906749963760376\n",
      "Test accuracy: 5.326560139656067\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 5.327   \u001b[0m | \u001b[0m 0.004927\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 118s 74ms/step - loss: 1.1015 - accuracy: 0.4284\n",
      "Test loss: 0.09757402539253235\n",
      "Test accuracy: 5.195935964584351\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 5.196   \u001b[0m | \u001b[0m 0.007925\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 115s 72ms/step - loss: 1.1517 - accuracy: 0.3711\n",
      "Test loss: 0.10731278657913208\n",
      "Test accuracy: 3.889695107936859\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 3.89    \u001b[0m | \u001b[0m 0.003107\u001b[0m |\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 114s 71ms/step - loss: 1.0671 - accuracy: 0.3979\n",
      "Test loss: 0.09564208984375\n",
      "Test accuracy: 5.3410738706588745\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 5.341   \u001b[0m | \u001b[0m 0.003081\u001b[0m |\n",
      "=====================================\n",
      "Iteration 0: \n",
      "\t{'target': 4.716981053352356, 'params': {'lr': 0.004228517846555483}}\n",
      "Iteration 1: \n",
      "\t{'target': 4.296081364154816, 'params': {'lr': 0.007231212485077366}}\n",
      "Iteration 2: \n",
      "\t{'target': 3.294629752635956, 'params': {'lr': 0.00010113231069171439}}\n",
      "Iteration 3: \n",
      "\t{'target': 5.703918933868408, 'params': {'lr': 0.003093092469055214}}\n",
      "Iteration 4: \n",
      "\t{'target': 5.07982611656189, 'params': {'lr': 0.0015528833190894193}}\n",
      "Iteration 5: \n",
      "\t{'target': 3.570391833782196, 'params': {'lr': 0.0010141520882110983}}\n",
      "Iteration 6: \n",
      "\t{'target': 3.4397676587104797, 'params': {'lr': 0.0019439760926389421}}\n",
      "Iteration 7: \n",
      "\t{'target': 5.3410738706588745, 'params': {'lr': 0.003521051197726173}}\n",
      "Iteration 8: \n",
      "\t{'target': 5.181422233581543, 'params': {'lr': 0.004027997994883633}}\n",
      "Iteration 9: \n",
      "\t{'target': 5.1233673095703125, 'params': {'lr': 0.005434285666633234}}\n",
      "Iteration 10: \n",
      "\t{'target': 5.37010133266449, 'params': {'lr': 0.002761237786148106}}\n",
      "Iteration 11: \n",
      "\t{'target': 5.13788104057312, 'params': {'lr': 0.006024380690034502}}\n",
      "Iteration 12: \n",
      "\t{'target': 5.471698045730591, 'params': {'lr': 0.01}}\n",
      "Iteration 13: \n",
      "\t{'target': 5.239477753639221, 'params': {'lr': 0.009480329785707536}}\n",
      "Iteration 14: \n",
      "\t{'target': 3.526850640773773, 'params': {'lr': 0.008738926243592307}}\n",
      "Iteration 15: \n",
      "\t{'target': 5.500725507736206, 'params': {'lr': 0.00653820192570272}}\n",
      "Iteration 16: \n",
      "\t{'target': 5.326560139656067, 'params': {'lr': 0.0049274385191790645}}\n",
      "Iteration 17: \n",
      "\t{'target': 5.195935964584351, 'params': {'lr': 0.007924726935973153}}\n",
      "Iteration 18: \n",
      "\t{'target': 3.889695107936859, 'params': {'lr': 0.0031069541240735595}}\n",
      "Iteration 19: \n",
      "\t{'target': 5.3410738706588745, 'params': {'lr': 0.0030806776442324412}}\n",
      "{'target': 5.703918933868408, 'params': {'lr': 0.003093092469055214}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'lr': (1e-4, 1e-2)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=10)\n",
    "\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_6 (Masking)          (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 24,146\n",
      "Trainable params: 24,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(Glob)\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.003, rho = 0.9), metrics=['acc', recall_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 726 samples, validate on 312 samples\n",
      "Epoch 1/30\n",
      " - 43s - loss: 0.3406 - acc: 0.9477 - recall_m: 0.9575 - val_loss: 0.1674 - val_acc: 0.9615 - val_recall_m: 0.9700\n",
      "Epoch 2/30\n",
      " - 42s - loss: 0.2016 - acc: 0.9518 - recall_m: 0.9563 - val_loss: 0.1643 - val_acc: 0.9615 - val_recall_m: 0.9700\n",
      "Epoch 3/30\n",
      " - 42s - loss: 0.1974 - acc: 0.9518 - recall_m: 0.9563 - val_loss: 0.1633 - val_acc: 0.9615 - val_recall_m: 0.9700\n",
      "Epoch 4/30\n",
      " - 42s - loss: 0.1956 - acc: 0.9518 - recall_m: 0.9563 - val_loss: 0.1633 - val_acc: 0.9615 - val_recall_m: 0.9700\n",
      "Epoch 5/30\n",
      " - 41s - loss: 0.1938 - acc: 0.9518 - recall_m: 0.9563 - val_loss: 0.1626 - val_acc: 0.9615 - val_recall_m: 0.9700\n",
      "Epoch 6/30\n",
      " - 42s - loss: 0.1920 - acc: 0.9518 - recall_m: 0.9563 - val_loss: 0.1629 - val_acc: 0.9615 - val_recall_m: 0.9700\n",
      "Epoch 7/30\n",
      " - 42s - loss: 0.1905 - acc: 0.9518 - recall_m: 0.9563 - val_loss: 0.1642 - val_acc: 0.9615 - val_recall_m: 0.9700\n",
      "Epoch 8/30\n",
      " - 42s - loss: 0.1884 - acc: 0.9518 - recall_m: 0.9563 - val_loss: 0.1650 - val_acc: 0.9615 - val_recall_m: 0.9700\n",
      "Epoch 9/30\n",
      " - 41s - loss: 0.1867 - acc: 0.9532 - recall_m: 0.9575 - val_loss: 0.1666 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 10/30\n",
      " - 42s - loss: 0.1824 - acc: 0.9532 - recall_m: 0.9575 - val_loss: 0.1691 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 11/30\n",
      " - 41s - loss: 0.1802 - acc: 0.9532 - recall_m: 0.9575 - val_loss: 0.1688 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 12/30\n",
      " - 42s - loss: 0.1740 - acc: 0.9532 - recall_m: 0.9575 - val_loss: 0.1826 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 13/30\n",
      " - 42s - loss: 0.1705 - acc: 0.9532 - recall_m: 0.9575 - val_loss: 0.1894 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 14/30\n",
      " - 43s - loss: 0.1625 - acc: 0.9545 - recall_m: 0.9575 - val_loss: 0.1902 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 15/30\n",
      " - 42s - loss: 0.1555 - acc: 0.9545 - recall_m: 0.9588 - val_loss: 0.1980 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 16/30\n",
      " - 43s - loss: 0.1493 - acc: 0.9573 - recall_m: 0.9613 - val_loss: 0.2143 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 17/30\n",
      " - 42s - loss: 0.1439 - acc: 0.9601 - recall_m: 0.9481 - val_loss: 0.2242 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 18/30\n",
      " - 42s - loss: 0.1433 - acc: 0.9601 - recall_m: 0.9588 - val_loss: 0.2088 - val_acc: 0.9583 - val_recall_m: 0.9675\n",
      "Epoch 19/30\n",
      " - 41s - loss: 0.1374 - acc: 0.9601 - recall_m: 0.9625 - val_loss: 0.2023 - val_acc: 0.9615 - val_recall_m: 0.9550\n",
      "Epoch 20/30\n",
      " - 42s - loss: 0.1302 - acc: 0.9614 - recall_m: 0.9625 - val_loss: 0.2129 - val_acc: 0.9583 - val_recall_m: 0.9525\n",
      "Epoch 21/30\n",
      " - 42s - loss: 0.1284 - acc: 0.9642 - recall_m: 0.9613 - val_loss: 0.2127 - val_acc: 0.9583 - val_recall_m: 0.9550\n",
      "Epoch 22/30\n",
      " - 41s - loss: 0.1460 - acc: 0.9587 - recall_m: 0.9504 - val_loss: 0.2172 - val_acc: 0.9583 - val_recall_m: 0.9650\n",
      "Epoch 23/30\n",
      " - 41s - loss: 0.1219 - acc: 0.9642 - recall_m: 0.9613 - val_loss: 0.2217 - val_acc: 0.9583 - val_recall_m: 0.9625\n",
      "Epoch 24/30\n",
      " - 42s - loss: 0.1164 - acc: 0.9642 - recall_m: 0.9650 - val_loss: 0.2374 - val_acc: 0.9551 - val_recall_m: 0.9625\n",
      "Epoch 25/30\n",
      " - 42s - loss: 0.1136 - acc: 0.9628 - recall_m: 0.9637 - val_loss: 0.2434 - val_acc: 0.9519 - val_recall_m: 0.9525\n",
      "Epoch 26/30\n",
      " - 42s - loss: 0.1079 - acc: 0.9656 - recall_m: 0.9613 - val_loss: 0.2614 - val_acc: 0.9583 - val_recall_m: 0.9625\n",
      "Epoch 27/30\n",
      " - 41s - loss: 0.1047 - acc: 0.9683 - recall_m: 0.9600 - val_loss: 0.2527 - val_acc: 0.9583 - val_recall_m: 0.9575\n",
      "Epoch 28/30\n",
      " - 41s - loss: 0.1286 - acc: 0.9628 - recall_m: 0.9404 - val_loss: 0.2453 - val_acc: 0.9519 - val_recall_m: 0.9500\n",
      "Epoch 29/30\n",
      " - 42s - loss: 0.0906 - acc: 0.9669 - recall_m: 0.9588 - val_loss: 0.2449 - val_acc: 0.9583 - val_recall_m: 0.9475\n",
      "Epoch 30/30\n",
      " - 42s - loss: 0.0915 - acc: 0.9711 - recall_m: 0.9450 - val_loss: 0.2654 - val_acc: 0.9551 - val_recall_m: 0.9500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=100, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()                                       \n",
    "plt.show()             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   varible_name  perturbation_effect\n",
      "17      컴퓨터/인터넷             0.105500\n",
      "6            기타             0.067070\n",
      "9       비즈니스/쇼핑             0.064833\n",
      "0    세션당 방문사이트수             0.037320\n",
      "7        뉴스/미디어             0.025902\n",
      "1        세션지속시간             0.016763\n",
      "8         문화/예술             0.014035\n",
      "3            게임             0.005174\n",
      "11       스포츠/레저             0.005075\n",
      "15        정치/사회             0.002527\n",
      "10        생활/건강             0.002033\n",
      "2     쇼핑사이트방문여부             0.001977\n",
      "5         교육/학교             0.001861\n",
      "4        경제/재테크             0.001658\n",
      "13        연예/오락             0.000948\n",
      "18        학문/사전             0.000616\n",
      "14           인물             0.000532\n",
      "12      여행/세계정보             0.000301\n",
      "16           종교             0.000023\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(X_train.reshape(1606*5000, 19))\n",
    "train_df.columns = ['세션당 방문사이트수','세션지속시간','쇼핑사이트방문여부' ,\n",
    "                    '게임', '경제/재테크', '교육/학교', '기타', '뉴스/미디어', '문화/예술', '비즈니스/쇼핑', '생활/건강', '스포츠/레저',\n",
    " '여행/세계정보', '연예/오락', '인물', '정치/사회', '종교', '컴퓨터/인터넷', '학문/사전']\n",
    "## Sensitivity Analysis\n",
    "importance_df = pd.DataFrame(np.zeros((19, 2)), columns=['varible_name', 'perturbation_effect'])\n",
    "def var_importance(model):\n",
    "    x = X_test # Get a sample of data\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(19):  # iterate over the three features\n",
    "        new_x = x.copy()\n",
    "        perturbation = np.random.normal(0.0, 0.2, size=new_x.shape[:2])\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5 #RMSE\n",
    "        importance_df.iloc[i,0] = train_df.columns[i]\n",
    "        importance_df.iloc[i,1] = effect\n",
    "        #print(f'Variable {i+1}, perturbation effect: {effect:.4f}')\n",
    "var_importance(model)\n",
    "importance_df = importance_df.sort_values(by='perturbation_effect', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perm = PermutationImportance(model, random_state=1).fit(X_test,y_test)\n",
    "#eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6023222208023071\n"
     ]
    }
   ],
   "source": [
    "#가전제품 f1-score: 0.7819220343082984\n",
    "#패션 accuracy: 0.7188029361269287\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_중순_가전제품, Y_중순_가전제품, test_size=0.3, random_state=42)\n",
    "#y_train = to_categorical(y_train)\n",
    "#y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_8 (Masking)          (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 24,146\n",
      "Trainable params: 24,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(Glob)\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc', recall_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 732 samples, validate on 315 samples\n",
      "Epoch 1/30\n",
      " - 23s - loss: 0.5931 - acc: 0.9221 - recall_m: 0.9455 - val_loss: 0.5181 - val_acc: 0.8984 - val_recall_m: 0.8985\n",
      "Epoch 2/30\n",
      " - 22s - loss: 0.4780 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.4447 - val_acc: 0.8984 - val_recall_m: 0.8985\n",
      "Epoch 3/30\n",
      " - 22s - loss: 0.4091 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3974 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 4/30\n",
      " - 22s - loss: 0.3634 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3639 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 5/30\n",
      " - 22s - loss: 0.3250 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3363 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 6/30\n",
      " - 22s - loss: 0.2953 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3286 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 7/30\n",
      " - 22s - loss: 0.2849 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3276 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 8/30\n",
      " - 23s - loss: 0.2795 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3289 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 9/30\n",
      " - 23s - loss: 0.2759 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3320 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 10/30\n",
      " - 22s - loss: 0.2735 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3334 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 11/30\n",
      " - 22s - loss: 0.2721 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3355 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 12/30\n",
      " - 22s - loss: 0.2711 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3360 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 13/30\n",
      " - 22s - loss: 0.2699 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3372 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 14/30\n",
      " - 22s - loss: 0.2695 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3379 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 15/30\n",
      " - 22s - loss: 0.2682 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3387 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 16/30\n",
      " - 22s - loss: 0.2673 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3392 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 17/30\n",
      " - 22s - loss: 0.2660 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3396 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 18/30\n",
      " - 22s - loss: 0.2650 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3399 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 19/30\n",
      " - 22s - loss: 0.2640 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3405 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 20/30\n",
      " - 22s - loss: 0.2629 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3407 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 21/30\n",
      " - 22s - loss: 0.2616 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3411 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 22/30\n",
      " - 22s - loss: 0.2612 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3414 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 23/30\n",
      " - 22s - loss: 0.2597 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3421 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 24/30\n",
      " - 22s - loss: 0.2585 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3423 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 25/30\n",
      " - 22s - loss: 0.2579 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3420 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 26/30\n",
      " - 22s - loss: 0.2564 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3427 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 27/30\n",
      " - 22s - loss: 0.2554 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3428 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 28/30\n",
      " - 22s - loss: 0.2536 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3436 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 29/30\n",
      " - 22s - loss: 0.2524 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3431 - val_acc: 0.8984 - val_recall_m: 0.8941\n",
      "Epoch 30/30\n",
      " - 23s - loss: 0.2508 - acc: 0.9235 - recall_m: 0.9255 - val_loss: 0.3450 - val_acc: 0.8984 - val_recall_m: 0.8941\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=200, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   varible_name  perturbation_effect\n",
      "6            기타             0.019017\n",
      "0    세션당 방문사이트수             0.018900\n",
      "9       비즈니스/쇼핑             0.017860\n",
      "17      컴퓨터/인터넷             0.011322\n",
      "1        세션지속시간             0.005882\n",
      "3            게임             0.004853\n",
      "2     쇼핑사이트방문여부             0.002543\n",
      "7        뉴스/미디어             0.002450\n",
      "15        정치/사회             0.002309\n",
      "5         교육/학교             0.001170\n",
      "4        경제/재테크             0.000860\n",
      "16           종교             0.000262\n",
      "11       스포츠/레저             0.000238\n",
      "10        생활/건강             0.000212\n",
      "12      여행/세계정보             0.000210\n",
      "18        학문/사전             0.000137\n",
      "13        연예/오락             0.000118\n",
      "8         문화/예술             0.000115\n",
      "14           인물             0.000049\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(X_train.reshape(X_train.shape[0] * X_train.shape[1], 19))\n",
    "train_df.columns = ['세션당 방문사이트수','세션지속시간','쇼핑사이트방문여부' ,\n",
    "                    '게임', '경제/재테크', '교육/학교', '기타', '뉴스/미디어', '문화/예술', '비즈니스/쇼핑', '생활/건강', '스포츠/레저',\n",
    " '여행/세계정보', '연예/오락', '인물', '정치/사회', '종교', '컴퓨터/인터넷', '학문/사전']\n",
    "\n",
    "## Sensitivity Analysis\n",
    "importance_df = pd.DataFrame(np.zeros((19, 2)), columns=['varible_name', 'perturbation_effect'])\n",
    "def var_importance(model):\n",
    "    x = X_test # Get a sample of data\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(19):  # iterate over the three features\n",
    "        new_x = x.copy()\n",
    "        perturbation = np.random.normal(0.0, 0.2, size=new_x.shape[:2])\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5 #RMSE\n",
    "        importance_df.iloc[i,0] = train_df.columns[i]\n",
    "        importance_df.iloc[i,1] = effect\n",
    "        #print(f'Variable {i+1}, perturbation effect: {effect:.4f}')\n",
    "var_importance(model)\n",
    "importance_df = importance_df.sort_values(by='perturbation_effect', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()                                       \n",
    "plt.show()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632478654384613\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_하순_가전제품, Y_하순_가전제품, test_size=0.3, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_9 (Masking)          (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 24,146\n",
      "Trainable params: 24,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc', recall_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 735 samples, validate on 315 samples\n",
      "Epoch 1/60\n",
      " - 14s - loss: 0.4634 - acc: 0.9456 - recall_m: 0.9536 - val_loss: 0.2975 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 2/60\n",
      " - 13s - loss: 0.2881 - acc: 0.9605 - recall_m: 0.9565 - val_loss: 0.2485 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 3/60\n",
      " - 13s - loss: 0.2290 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2319 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 4/60\n",
      " - 13s - loss: 0.1996 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2285 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 5/60\n",
      " - 13s - loss: 0.1920 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2279 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 6/60\n",
      " - 12s - loss: 0.1868 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2290 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 7/60\n",
      " - 13s - loss: 0.1861 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2324 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 8/60\n",
      " - 12s - loss: 0.1816 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2335 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 9/60\n",
      " - 13s - loss: 0.1806 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2352 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 10/60\n",
      " - 13s - loss: 0.1759 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2358 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 11/60\n",
      " - 13s - loss: 0.1715 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2367 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 12/60\n",
      " - 13s - loss: 0.1814 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2364 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 13/60\n",
      " - 13s - loss: 0.1707 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2362 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 14/60\n",
      " - 13s - loss: 0.1741 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2348 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 15/60\n",
      " - 13s - loss: 0.1715 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2354 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 16/60\n",
      " - 12s - loss: 0.1716 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2360 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 17/60\n",
      " - 12s - loss: 0.1692 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2377 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 18/60\n",
      " - 12s - loss: 0.1698 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2380 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 19/60\n",
      " - 13s - loss: 0.1666 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2371 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 20/60\n",
      " - 12s - loss: 0.1625 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2370 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 21/60\n",
      " - 12s - loss: 0.1596 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2386 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 22/60\n",
      " - 13s - loss: 0.1639 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2382 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 23/60\n",
      " - 13s - loss: 0.1692 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2360 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 24/60\n",
      " - 13s - loss: 0.1581 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2384 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 25/60\n",
      " - 13s - loss: 0.1666 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2399 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 26/60\n",
      " - 13s - loss: 0.1578 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2380 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 27/60\n",
      " - 13s - loss: 0.1626 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2413 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 28/60\n",
      " - 13s - loss: 0.1642 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2382 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 29/60\n",
      " - 13s - loss: 0.1637 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2370 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 30/60\n",
      " - 13s - loss: 0.1617 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2380 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 31/60\n",
      " - 13s - loss: 0.1517 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2430 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 32/60\n",
      " - 13s - loss: 0.1541 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2489 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 33/60\n",
      " - 12s - loss: 0.1591 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2514 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 34/60\n",
      " - 13s - loss: 0.1563 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2533 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 35/60\n",
      " - 13s - loss: 0.1480 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2494 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 36/60\n",
      " - 13s - loss: 0.1511 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2490 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 37/60\n",
      " - 12s - loss: 0.1529 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2379 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 38/60\n",
      " - 13s - loss: 0.1476 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2421 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 39/60\n",
      " - 13s - loss: 0.1488 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2520 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 40/60\n",
      " - 13s - loss: 0.1486 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2570 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 41/60\n",
      " - 13s - loss: 0.1403 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2645 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 42/60\n",
      " - 13s - loss: 0.1489 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2671 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 43/60\n",
      " - 13s - loss: 0.1353 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2622 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 44/60\n",
      " - 12s - loss: 0.1449 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2583 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 45/60\n",
      " - 13s - loss: 0.1445 - acc: 0.9619 - recall_m: 0.9596 - val_loss: 0.2502 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 46/60\n",
      " - 13s - loss: 0.1357 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2348 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 47/60\n",
      " - 13s - loss: 0.1399 - acc: 0.9619 - recall_m: 0.9585 - val_loss: 0.2605 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 48/60\n",
      " - 13s - loss: 0.1366 - acc: 0.9619 - recall_m: 0.9596 - val_loss: 0.2653 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 49/60\n",
      " - 12s - loss: 0.1311 - acc: 0.9633 - recall_m: 0.9617 - val_loss: 0.2765 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 50/60\n",
      " - 13s - loss: 0.1345 - acc: 0.9633 - recall_m: 0.9617 - val_loss: 0.2816 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 51/60\n",
      " - 12s - loss: 0.1253 - acc: 0.9633 - recall_m: 0.9617 - val_loss: 0.2750 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 52/60\n",
      " - 13s - loss: 0.1285 - acc: 0.9633 - recall_m: 0.9617 - val_loss: 0.2619 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 53/60\n",
      " - 13s - loss: 0.1284 - acc: 0.9605 - recall_m: 0.9575 - val_loss: 0.2534 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 54/60\n",
      " - 13s - loss: 0.1350 - acc: 0.9633 - recall_m: 0.9606 - val_loss: 0.2630 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 55/60\n",
      " - 13s - loss: 0.1279 - acc: 0.9619 - recall_m: 0.9596 - val_loss: 0.2766 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 56/60\n",
      " - 12s - loss: 0.1252 - acc: 0.9646 - recall_m: 0.9627 - val_loss: 0.2794 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 57/60\n",
      " - 13s - loss: 0.1227 - acc: 0.9633 - recall_m: 0.9627 - val_loss: 0.2744 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 58/60\n",
      " - 13s - loss: 0.1214 - acc: 0.9646 - recall_m: 0.9627 - val_loss: 0.2724 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 59/60\n",
      " - 13s - loss: 0.1187 - acc: 0.9660 - recall_m: 0.9649 - val_loss: 0.2790 - val_acc: 0.9429 - val_recall_m: 0.9429\n",
      "Epoch 60/60\n",
      " - 12s - loss: 0.1172 - acc: 0.9633 - recall_m: 0.9616 - val_loss: 0.2621 - val_acc: 0.9429 - val_recall_m: 0.9429\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=60, batch_size=500, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(X_train.reshape(X_train.shape[0] * X_train.shape[1], 19))\n",
    "train_df.columns = ['세션당 방문사이트수','세션지속시간','쇼핑사이트방문여부' ,\n",
    "                    '게임', '경제/재테크', '교육/학교', '기타', '뉴스/미디어', '문화/예술', '비즈니스/쇼핑', '생활/건강', '스포츠/레저',\n",
    " '여행/세계정보', '연예/오락', '인물', '정치/사회', '종교', '컴퓨터/인터넷', '학문/사전']\n",
    "## Sensitivity Analysis\n",
    "importance_df = pd.DataFrame(np.zeros((19, 2)), columns=['varible_name', 'perturbation_effect'])\n",
    "def var_importance(model):\n",
    "    x = X_test # Get a sample of data\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(19):  # iterate over the three features\n",
    "        new_x = x.copy()\n",
    "        perturbation = np.random.normal(0.0, 0.2, size=new_x.shape[:2])\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5 #RMSE\n",
    "        importance_df.iloc[i,0] = train_df.columns[i]\n",
    "        importance_df.iloc[i,1] = effect\n",
    "        #print(f'Variable {i+1}, perturbation effect: {effect:.4f}')\n",
    "var_importance(model)\n",
    "importance_df = importance_df.sort_values(by='perturbation_effect', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()                                       \n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
