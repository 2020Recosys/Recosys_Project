{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Masking\n",
    "from keras.optimizers import RMSprop\n",
    "import xgboost as xgb\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled = pd.read_csv('./X_resampled_1-2.csv')\n",
    "print(\"X_resampled loaded!\")\n",
    "Y_resampled = pd.read_csv('./Y_resampled_1-2.csv')\n",
    "Y_resampled = np.array(Y_resampled)\n",
    "print(\"Y_resampled loaded!\")\n",
    "\n",
    "# sample data\n",
    "# X_resampled = np.random.randn(100, 10)\n",
    "# Y_resampled = [0] * 70 + [1] * 30\n",
    "# Y_resampled = np.array(Y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def dnn_models():\n",
    "    dnn_model = Sequential()\n",
    "    dnn_model.add(Dense(32, activation='relu', input_shape=(X_resampled.shape[1],)))\n",
    "    dnn_model.add(Dense(16, activation='relu'))\n",
    "    dnn_model.add(Dense(1, activation='sigmoid'))\n",
    "    dnn_model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc', f1_m, precision_m, recall_m])\n",
    "    return dnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(10, shuffle=True, random_state=42).split(X_resampled, Y_resampled)\n",
    "print(\"Made cv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_for_one(algorithm):\n",
    "    clf = make_pipeline(SMOTE(random_state=0), algorithm)\n",
    "\n",
    "    # scores basket\n",
    "    accuracy = []\n",
    "    f1 = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    idx = 1\n",
    "    for train_index, test_index in cv:\n",
    "        print(\"cv = \", idx)\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = np.take(Y_resampled, train_index, axis=0), np.take(Y_resampled, test_index, axis=0)\n",
    "        \n",
    "        # model train, test\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "        f1.append(f1_score(y_true=y_test, y_pred=y_pred))\n",
    "        precision.append(precision_score(y_true=y_test, y_pred=y_pred))\n",
    "        recall.append(recall_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "        # initalize\n",
    "        X_train, X_test = [], []\n",
    "        y_train, y_test = [], []\n",
    "        idx += 1\n",
    "    \n",
    "    print(\"---\"*8)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"---\"*8)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"---\"*8)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"---\"*8)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"---\"*8)\n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clf1, f1_clf1, precision_clf1, recall_clf1 = cv_for_one(algorithm=GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clf2, f1_clf2, precision_clf2, recall_clf2 = cv_for_one(algorithm=DecisionTreeClassifier(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_clf3, f1_clf3, precision_clf3, recall_clf3 = cv_for_one(algorithm=xgb.XGBClassifier(learning_rate = 0.05, n_estimators=300, max_depth=3, verbosity=2, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_clf4, f1_clf4, precision_clf4, recall_clf4 = cv_for_one(algorithm=LogisticRegression(max_iter=1000, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_clf5, f1_clf5, precision_clf5, recall_clf5 = cv_for_one(algorithm=LinearSVC(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_clf6, f1_clf6, precision_clf6, recall_clf6 = cv_for_one(algorithm=KerasClassifier(build_fn=dnn_models, epochs=25, batch_size=1000, verbose=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
